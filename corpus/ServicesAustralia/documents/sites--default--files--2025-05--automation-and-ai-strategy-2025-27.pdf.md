---
url: https://www.servicesaustralia.gov.au/sites/default/files/2025-05/automation-and-ai-strategy-2025-27.pdf
title: Automation and Artificial Intelligence Strategy 2025-27
scrapedAt: 2026-02-16T22:09:28.539Z
source: servicesaustralia.gov.au
---
# Automation and Artificial Intelligence Strategy 2025-27

# Contents

A message from the Chief Customer Officer .... 3

Introduction .

Current State.. . 5

Who we serve. . 6

Types of automation. 8

Future State and how we will achieve it ..

Priority 1: Build trust with customers, staff and strategic partners. 9

Priority 2: Human-led initiatives improving service delivery where it is beneficial for our customers and staff.. 12

Priority 3: Ensure consistency in governance, assurance and investment frameworks .............. 14

Priority 4: Contemporary legislation and simplified policy .. . 16

Priority 5: Uplift our workforce capability and capacity required to develop and manage automation and AI safely, ethically, and responsibly . 17

Priority 6: Modular, connected and standardised systems to enable scalable initiatives to be delivered. .... 18

Measuring success... 19

# A message from the Chief Customer Officer

This Automation and Artificial Intelligence (AI) Strategy marks an important step in Services Australia’s efforts to harness the potential of automation and AI safely and responsibly. These capabilities can modernise and enhance service delivery for both our staff and customers, as we strive to make government services simple so people can get on with their lives. Automation and AI also have the capacity to enhance efficiency, support more-informed decisions, and elevate the overall experience for the people we serve.

Our approach is grounded in human-centred design to ensure that our use of automation and AI benefit customers and staff. This human-centred approach has also been used to develop our strategy, engaging stakeholders across government as well as customer and staff advocacy groups, including the Independent Advisory Board for Government Services.

Artificial intelligence is now in the present, not just the future. Increasingly, Australians have leveraged automation for several years and now we’re stepping into the next generation of digital technology and exploring how we can harness new capabilities to deliver improved and faster government services. This strategy outlines how we’re going to responsibly integrate automation and AI, ensuring its design, application and governance will be human-centred, safe, transparent, ethical, legal and fair.

While we’re optimistic about the potential benefits, we understand the barriers we may face implementing initiatives that create real value, and we are conscious of balancing the risks. This is why we are establishing robust and responsive governance, assurance, and decision-making artefacts that adhere to whole of government frameworks and policies, best practice and relevant standards. This includes the appointment of an AI Accountable Official.

The agency has already made substantial progress in establishing the foundations required to safely and responsibly apply automation and AI capabilities. This strategy builds on these foundations and recognises our role in shaping the Government’s future response to automation and AI. We’ll focus on developing the necessary culture, practices, processes, and governance to ensure we have a strong automation and AI capability into the future. This includes fostering an environment that supports automation and AI innovation, so we can better meet the needs of customers, staff and stakeholders.

We’re shaping a future where automation and AI help us to deliver better outcomes, contributing to our vision to make government services simple, so people can get on with their lives.

# Jonathon Thorpe

Chief Customer Officer Service Delivery Excellence

# Introduction

Automation and artificial intelligence (AI) technologies are transforming how we live and work. Services Australia touches the lives of almost everyone, which is why we are harnessing automation and AI to enhance our operations and services, where it is beneficial to our customers and staff. We have a goal of becoming a world leader in government service delivery, to become an example of best practice in safely, securely and transparently using automation and AI to make government services simple so people can get on with their lives.

This is crucial when we consider the magnitude of our work. On any given week, we handle around 10 million customer interactions, $90 %$ of which are digital. In 2023-24, we managed 1.1 billion online interactions and 468.5 million total claims.1

Use of automation and AI for predictable and repetitive work will enable our staff to spend more time on providing services and support for people with complex needs or those experiencing vulnerability. This Automation and AI Strategy 2025-27, which sets the direction for automation and AI in Services Australia, will help us achieve our goal.

We’re committed to ensuring automation and AI use in the agency will be human-centric, safe, responsible, transparent, fair, ethical and legal. Our decisions are anchored by our Experience Design Principles, Australia’s AI Ethics Principles,2 and the principles outlined in the Automated Decision-Making Better Practice Guide.3 This is also supported by our customer-centred design approach, ensuring customers and staff are at the heart of everything we do.

Our approach is aligned to key government policies, such as the Policy for the responsible use of AI in government 4 and the National framework for the assurance of artificial intelligence in government,5 which will help us in establishing the appropriate governance, assurance and systems. Additionally, our approach to automation and AI is informed by our strategic partners across various industries, including advocacy groups, unions, academia, government, and industry, contributing to a culture of listening, learning and collaborating. We will use these partnerships, policies, and frameworks to generate valuable and viable solutions, swiftly implementing high-value initiatives in a controlled manner.

Our workforce is central to the success of automation and AI. We’re investing in our staff to train, build and acquire the skills needed to securely adopt and maintain these technologies, in line with the Australian Public Service (APS) Workforce Strategy.6

The success of this strategy depends on recognising, understanding and addressing the barriers we will face in adopting automation and AI. To address the barriers, we have identified 6 priorities: (1) building trust; (2) human-led initiatives; (3) mature governance and investment frameworks; (4) standardised legislation and simplified policy; (5) uplifting workforce capability and capacity; and (6) modular, connected and standardised platforms and systems. These priorities are described further below.

Our future state will position us as a best practice organisation where automation and AI is used responsibly, ethically and safely. This will be supported by effective frameworks, policies, standards and procedures, informed by whole-of-government approaches and strategic partners. Our workforce will be equipped with the right skills and uplifted in their approach to work, resulting in improved capacity, simplified processes and an environment that fosters innovation. Finally, automation and AI aim to give our customers faster outcomes, more consistently, making government services simple so people can get on with their lives.

# Current State

In 2023-24 the agency processed 468.5 million claims across our portfolios, including Social Security and Welfare, Child Support, and Health. With over 1.1 billion online interactions each year, there is a significant opportunity for automation and AI to enhance the way we deliver services. On 30 October 2024, we had over 600 automated processes supporting our staff and customers.

Our Transparency Statement outlines the areas that we are using Automation and AI in and the way in which we will ensure these technologies are developed, implemented and assured. We use automation and AI in Services Australia to support the delivery of services where it is helpful for our customers and staff. For example, Optical Character Recognition (OCR) and other similar technologies are being used to extract customer responses from digital images and forms, supporting our staff to process claims, such as disaster payments, quickly.

Tools such as the myGov Digital Assistant respond to millions of customer enquiries each year and provide customers with key information on how to access our services. In the telephony channel, our Intelligent Voice Response (IVR) service helps route calls in a smarter way, using AI. We use AI to identify patterns in data. For example, finding themes and trends in questions customers ask our digital assistants.

Varying levels of risk, predictability, impact and scale means each solution must be assessed individually through assurance and governance processes, with multi-disciplinary teams from both within and external to the agency. Included in these assurance and governance processes are safeguards to ensure we continue to use automation and AI responsibly, as outlined in our Transparency Statement1, including:

experimenting with automation and AI in closely controlled offline environments to explore their appropriateness and safety

only using automation and AI outside these environments when we have identified and implemented controls to protect against any potential negative impacts

evaluating initiatives against assurance and governance requirements before implementation continuing to monitor and evaluate, and immediately pausing any systems if they stop meeting assurance and governance requirements

having a human ‘in the loop’ to check AI outputs, where appropriate

building staff capabilities through training programs so they can confidently use automation and AI technologies responsibly

regularly seeking feedback from users, including staff and customers

collaborating with strategic partners from government, industry, academia, and advocacy groups to help guide and support strategic decisions

aligning and implementing whole-of-government policies, frameworks and best practices, including Australia’s AI Ethics Principles, National framework for the assurance of artificial intelligence in government and compliance with each requirement under the Policy for responsible use of AI in government.

# Vision

Automation and AI will assist in delivering our vision ‘to make government services simple so people can get on with their lives’. Our corporate plan principles – simple, helpful, respectful, and transparent – guide us to uplift the experience of our customers and staff, which can be enhanced using automation and AI.7

# Automation and AI Objective

Our objective is for automation and AI to enable improved and faster government services while balancing safety and security. The governance and use of automation and AI will be transparent and accountable to the Australian public, enabling evidence-based decision making and oversight.

We will leverage automation and AI where appropriate to improve the customer and staff experience, reduce costs, increase service integrity, and enhance the agency’s reputation to build trust. Our customers will experience streamlined and faster services with simpler touch points, enabling our staff to provide more tailored support to customers in need.

# Definitions

The agency defines automation as:

‘an enabler for business using the application of technology to complete tasks’.

Services Australia uses automation to reduce and remove large amounts of repetitive, rules-based tasks. This allows us to focus on delivering value adding activities and providing tailored support to customers in need.

The agency adopts the OECD definition of an AI system:8 ‘a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment.’

# Who we serve

We’re enabling more transparent and trustworthy services organised around the needs of our customers and staff, aligned to government direction and informed by strategic partners.

# Our customers

Services Australia interacts with almost everyone. Because of this, customer-centricity is vital in providing reliable and accessible services, when and how they are needed.9

Our customer approach allows us to hear firsthand from diverse customers, to understand their challenges and opportunities and improve the way we interact with them. This means hearing all voices and perspectives, such as vulnerable customers, by listening through varied channels and considering commitments such as the National Agreement on Closing the Gap.

It applies to and encompasses automation and AI technologies as key to enabling capability, ensuring solutions are human-led. It enables us to modernise and improve how we deliver services, so our customers experience faster claim outcomes and quicker payments. We anticipate that, when deployed in specific use cases in a safe and responsible manner, automation and AI will continue to enhance accuracy and consistency, contributing to higher levels of customer satisfaction.

# Our workforce

Key to success is ensuring automation and AI empowers our workforce and improves staff engagement and satisfaction. To achieve this, we must consider how we can leverage automation and AI to address staff pain points, whilst improving workforce readiness for technological advancements. Critically, automation and AI will be used to complement the unique skills and capabilities of our staff, not replace them.

Our approach is to foster innovation across the agency, including the frontline, ensuring we harness operational expertise to solve problems responsibly, at scale and speed. For the right use cases, leveraging automation and AI can support staff to deliver improved and faster services. For example, we can simplify workflows, streamline processes giving staff more time to focus on high value activities that require human creativity and problem-solving.

We anticipate that AI and/or automation will have the potential to enhance workforce engagement and productivity in 6 ways:

1. Automating repetitive tasks allowing staff to focus on more complex and creative work, reducing monotony and promoting job satisfaction.10
2. Enhancing decision-making regarding initiatives that impact staff.11,12
3. Personalising learning and development by identifying individual strengths and growth areas to tailor training programs that uplift the skills of our staff.13
4. Enhancing safety and monitoring of workplace conditions and workload fluctuations, ensuring safety standards are met and alerting managers to potential hazards.14
5. Facilitating flexible work arrangements through virtual collaboration, project management, and communication tools.15
6. Enhancing communication with customers and within teams, ensuring timely information exchange and reducing misunderstandings.16

Our goal is to create a more engaging and satisfying work environment by effectively responding to the needs of our staff using automation and AI. To complement this, it is vital our staff are skilled and knowledgeable with automation and AI technologies and how we’re using them in the agency – this is explored further under Priority 5. In turn, our staff will be equipped to contribute to steward the community through delivery transformations that may occur with automation and AI.17

# Strategic Partners

Strategic partnerships are core to understanding our customers’ needs across all channels and delivering the best outcomes for all stakeholders. Strategic partners include Advocacy Groups, unions such as the Community and Public Sector Union (CPSU), federal government partners, state governments, academia, and international partners.

Uplifting our commercial and non-commercial partnering capability, as it relates to automation and AI, is an ongoing priority. This is critical to facilitate early co-design of initiatives, understanding emerging concerns or issues within the community, and ensuring robust and evidenced based decision making, as it relates to automation and AI. Our goal is to establish an ecosystem of partners that collaboratively build maturity of automation and use of AI technologies in the agency.

# Types of automation

Automation used within the agency is grouped into 3 solutions (see figure 1). With varying levels of predictability, impact, and scale, across rules-based, adaptive and intelligent automation, each capability will be assessed for their unique attributes by multi-disciplinary teams.

With approximately $9 5 %$ of the agency's automations rules-based, these solutions are further classified into three categories:

Straight Through Processing (STP) and End to End Automation – a solution that automates a process (like a claim) from beginning to end. It uses the automation framework business rules to identify if a claim or process is suitable for an automated outcome.

Process Step Automation (PSA) and Partial Claim Automation (PCA) – a solution that works with STP. PSA and PCA allow service officers to action specific tasks within a claim or activity that require

manual assessment. Once these tasks are completed, the claim or activity progresses for an automated outcome.

Digitally Enabled Processing (DEP) – technology that automates repetitive, high volume, rules-based processes. It logs into applications, navigates as a human operator by gathering and inputting data from systems.

![](https://www.servicesaustralia.gov.au/sites/default/files/2025-05/images/8370f2456cee3a36af61f429c123ac42dfafce8b2a84c7f207e2551ffaa6537f.jpg)

Figure 1 Automation grouping in the agency.

In the diagram above, intelligent and rules-based solutions use technology to complete tasks. We’re experimenting with and expanding into the Adaptive and Intelligent automation spaces. Intelligent automations include OCR and IVR, while Adaptive automations include chat bots, support with error codes and other Large Language Models (LLM).

# Future State and how we will achieve it

Over the next 3 years, we will work to remove identified potential barriers and achieve our vision by working toward six coordinated priorities.

# Priority 1: Build trust with customers, staff and strategic partners

Barrier: A trust deficit with stakeholders (including customers, staff and strategic partners)

Context: Stakeholders have varying levels of trust in automation and AI systems, depending on its application. Failing to actively engage with customers, staff, advocacy groups, industry and academia may compromise our understanding of the context in which automation and AI should be used and the controls that need to be in place. This may negatively impact trust and therefore success in harnessing these emerging technologies.

Critically, failing to deploy oversight tools, such as monitoring for accuracy and reliability, codes of conduct, independent ethical review boards, audits and adherence to standards will also impede trust and confidence.18

Research by Gartner highlights that failing to transparently quantify the benefits of automation and AI projects can hinder adoption, especially as some outcomes, such an improved experience, are difficult to quantify.19

Building trust with customers and staff is a key pillar to successfully implementing automation and AI solutions. $^ { 2 0 } \\mathsf { A }$ government survey found that the 2 biggest factors in building trust in AI for Australians are:

1. Protecting personal information $( 7 3 % )$
2. Being transparent about how and where AI is used $( 6 7 % )$

Limited trust is driven by the real or perceived risks associated with using automation and AI including legal and ethical concerns, misinformation, transparency and explainability, safety and security, industry concentration, environmental impact and job loss.

We will seek to address this by:

• ensuring decisions are documented, including the decision maker/accountable officers and options considered ensuring decisions are robust, evidenced based, defensible and explainable ensuring solutions and outputs are human-led with active scrutiny by and consideration given to diverse cohorts including staff, legal advisers, advocacy groups and subject matter experts ensuring we have defined the data we collect and how it is used promoting transparency regarding when and how data, automation and AI is used providing opt out options and "off" switches by design

# Protecting personal information

Our data policies are designed to ensure the secure and effective management of data across the organisation and across technologies.

These policies complement and support the broader goals of the Data and Digital Government Strategy which aims to deliver simple, secure and connected public services through world-class data and digital capabilities.21 The Data and Digital Strategy details the barriers in place to limit the use of sharing and releasing data. It also recommends moving from a risk-averse approach to one based on transparency and treating data as an asset.

In line with our agency data policies, some data, including personal, sensitive, protected and staff information, must be closely held and only shared when necessary, appropriate, and lawful. Other data may be underused or siloed, due to a lack of awareness of its existence, a lack of access to the right tools or capabilities, legislative and other barriers. In addition to these principles, the agency will endeavour to balance its use of data with emerging public expectations, Australian Privacy reform and overall benefit to the customer.

# Transparency and nurturing productive partnerships

In the spirit of transparency, there is a need to provide customers and staff with the ability to understand how and why decisions are reached. Where appropriate, we will ensure automation and AI used in initiatives are reviewed by an interdepartmental committee, including compliance and non-compliance reporting, to inform design and assurance by policy partners.

In addition, we will publish a transparency statement that outlines our approach to AI adoption, in compliance with the DTA’s Standard for AI Transparency Statements22 and the Policy for the responsible use of AI in government. It will be reviewed and updated annually (or sooner if there are significant changes to our approach to AI), providing our customers and the public up to date information on our use of AI, including:

compliance with the policy • measures to monitor effectiveness of deployed AI systems efforts to protect the public against negative impacts

# Strategic Partners

Transparent and effective partnerships are critical to the success of automation and AI as they underpin government and community trust in our agency. They will ensure automation and AI solutions are data driven, informed by global best practice, industry experts and leading academic research. Our partners will support us to identify opportunities, enable legislative reform and deliver strategic and customer-centred outcomes.

Through active collaboration, our partners help mature the agency’s automation and AI capability. Building partnerships across various sectors will ensure there is a wide pool of perspectives from which the agency can proactively draw on.

Strategic partners will align to common goals to:

enhance our ability to operationalise legislation and automation and AI policies in a service delivery environment receive input from key advocacy groups on how automation and AI can be optimised to meet customer needs reduce duplicated of effort increase utilisation of talent • access contemporary technologies and business practices

Our partnerships are established to facilitate a broad suite of approaches. This is underpinned by contemporary and robust methodologies for effectively engaging and managing partner relationships, supporting the agency to deliver simple, fit-for-purpose services. Strategic partners fall in one of the categories shown in figure 2: government, academia, advocates, industry or international. Identifying which sector a partner aligns to is a critical step in understanding how we may create mutually beneficial value from the relationship.

![](https://www.servicesaustralia.gov.au/sites/default/files/2025-05/images/d563bf9044edd5ccea4f01d6aabe7114236e90407d3e3b8679bcb3f6218c4749.jpg)

Figure 2 Strategic Partnership Groupings

# Building trust through AI

We’re working to ensure our public-facing resources and digital presence, like our websites, are optimised for easier AI consumption. Where we can, we will make it easier for external AI to extract the correct information and verify our content for accuracy. Our content governance processes will help ensure customers using AI tools are presented with information about Australian payments and services that is up to date, reliable and relevant. Similarly, we’ll uplift agency information management practices, so the AI tools we build and use to support our customers provide consistent, quality outputs. We’ll continue to optimise content in the public domain and explore new technologies, to build trust with Australians.

# Priority 2: Human-led initiatives improving service delivery where it is beneficial for our customers and staff

Barrier: Technology drives transformation, not people

Context: Harvard Business Review notes "the smartest, most nimble, and most innovative enterprises will be Human Enterprises where ‘business transformation’ is in fact human-led transformation aided by technology".23

This is further supported by insights published by the Boston Consulting Group where they hypothesise that successful ventures are problem oriented.24

Accordingly, if solutions are not human-centric, anchored on a genuine customer or staff need, short-term and long-term value will be compromised.

Our approach to innovation highlights our commitment to focusing on sustainable innovation to practice ethical, human-centred design to develop solutions that solve the right problems while doing the least harm and creating positive change. This extends to automation and AI – identifying opportunities first and considering if automation or AI is suitable to fill the need. Innovation comes from all places, including staff, customers, and strategic partners. For staff, these ideas are captured in the Innovation Exchange portal, customers through the customer listening channels and with strategic partners through ongoing engagements.

To manage and prioritise ideas that may be suitable for an automation and AI solution, we’re adopting a portfolio approach to uplift the agency’s investment planning for automation and AI opportunities, ensuring alignment to our broader strategic priorities. As automation or AI opportunities are identified, they are assessed on:

• the positive impact they will deliver to customers, staff and government

• the effort they require to be delivered successfully

• enterprise readiness for the initiative

• the risk of delivering or not delivering the initiative

This assessment ensures that ICT capability, business owners, system owners, enabling areas and our strategic partners are positioned to collaboratively, ethically and safely deliver accelerated, impactful initiatives that benefit customers and staff.

# Our Principles

The principles we adhere to keep us aligned to our ‘why’, guide our decisions and ensure we remain true to our commitments. These principles include our Experience Design Principles, Australia’s AI Ethics Principles, and the Commonwealth Ombudsman’s Automated Decision-Making Better Practice Guide.

Our principles enable objective decision making and alignment among all parties on the automation and AI governance, planning, design, and delivery pipeline in the agency.

|     |     |
| --- | --- |
| Services Australia's Experience Design Principles | Australia's Al Ethics Principles and Commonwealth Ombudsman's Automated Decision- Making Better Practice Guide |
| Simple • | Human, social and environmental wellbeing |
| Inclusive • | Human-centred values • |
| Tailored • | • Fairness |
| Connected | Privacy protection and security |
| Transparent • | Reliability and safety |
| Safe • | Transparency and explainability |
| Trustworthy | Contestability |
|  | Accountability |

# Priority 3: Ensure consistency in governance, assurance and investment frameworks

Barrier: Outdated, siloed or undervalued governance and planning functions

Context: Research by the Human Technology Institute suggests that traditional approaches to IT governance are not appropriate for emerging technologies, including AI, due to the rate of change and the potential for limited predictability, traceability and explainability.25

Accordingly, a universal barrier to enabling adaptive, apt and streamlined governance is not establishing or re-imagining existing frameworks to suit a dynamic environment.

Automation and AI in the agency will be guided by a set of whole-of-government and agency governance frameworks and processes, enabling us to make decisions consistent with our vision, values, principles, risk appetite and governance requirements. This will promote consistency, contestability and accountability, and strengthen guardrails established to protect customers and staff.

Specifically, we recognise that ethical considerations, principles of administrative law and compliance with legislative requirements must be considered in the design of automated processes and AI solutions, with appropriate oversight by the APS.

In implementing its response to the Report of the Royal Commission into the Robodebt Scheme, the Government will consider establishing a body, or expanding the functions of an existing body, with the power to monitor and audit Automated Decision Making (ADM) processes.

Additionally, the DTA Policy for the responsible use of AI in government recognises the need to identify an accountable official(s) in the agency. Accountable officers will:

• be accountable for the implementation of the DTA policy • notify the DTA of high-risk AI uses • be a contact point for whole-of-government AI coordination • engage in whole-of-government AI forums and processes • keep up to date with changing requirements as they evolve over time.

Services Australia has assigned responsibilities of the Accountable Official to the General Manager, Automation and Architecture (SES Band 2).

# Government Frameworks

We will consider and implement the appropriate whole-of-government policies and frameworks, which will help keep us aligned to our ‘how’. This includes the Commonwealth Ombudsman’s Automated Decision-making Better Practice Guide, a practical tool for the agency when implementing automated solutions. This guide emphasises that Australian Government agencies must ensure their automated systems comply with administrative law principles of legality, fairness, rationality and transparency, as well as privacy requirements and human rights obligations.

Additionally, we’ll consider alignment to the National Framework for the assurance of artificial intelligence in government, endorsed by the Data and Digital Ministers Meeting (DDMM).26 In 2024, we participated in the pilot for this framework, which sets a nationally consistent approach to AI, based on Australia’s 8 AI Ethics Principles, designed to ensure AI is safe, secure, and reliable, helping to:

• achieve safer, more reliable and fairer outcomes for all Australians

reduce the risk of negative impact on those affected by AI applications practice the highest ethical standards for businesses and governments when designing, developing and implementing AI.

Cornerstones of the framework are 5 mechanisms that ensure effective application of the ethics principles: governance, data governance, a risk-based approach, standards and procurement.

# Governance and Assurance

To build and maintain trust in the agency’s automation and AI capability, initiatives need to meet the agreed governance and assurance requirements before they start. This includes engagement with various internal and external stakeholders, services, and governing bodies for approval to progress automation and AI initiatives in the agency. This is determined using a scoping and categorisation tool to decide if an automation or AI initiative has a high, medium, low or no risk profile. Where an AI initiative is identified as high risk, we’ll notify the DTA via email, in line with the Policy for the Responsible Use of AI in Government. This will support in building visibility of AI across government, and to inform the development of further risk mitigation approaches.

Our governance and assurance mechanisms have checkpoints embedded throughout the relevant phases of our initiative pathway, ensuring we effectively manage risk and compliance. In addition, Services Australia is considering a review of historical automation processes to ensure they abide by the government and agency’s endorsed governance and assurance frameworks and remain consistent with the agency vision, values and principles.

Governance arrangements are critical for ensuring the automation and AI capability achieves intended outcomes and is fit for purpose. It requires working across groups to remove barriers and produce new solutions to complex problems. The authority and support of senior decision-makers safeguards the automation and AI capability to achieve its objectives.

# Priority 4: Contemporary legislation and simplified policy

Barrier: Legislation and policy that doesn’t enable the safe and responsible use of automation and AI technologies, particularly at the rate it is evolving and maturing.

Context: Identify where lagging legislation and policy acts as a barrier to the safe and responsible use of automation and AI technologies, and work with stakeholders and strategic partners to reform it.27

The complexity and interdependencies within existing laws and regulations can present a significant barrier to reform. Accordingly, a balanced approach will be required to ensure reforms provide clarity and fairness, while maintaining the necessary legal protections and standards.

Consistent legal frameworks for using automation and AI will ensure that the agency can operate ethically, fairly, legally and with appropriate safeguards. As is emerging in the European Union, consideration should be given to separate legal frameworks to allow for the differences between automation and AI.28

The Attorney-General’s Department (AGD) is leading the development of a standard legislative framework, in which automation in government services can operate, as recommended in the Royal Commission into the Robodebt Scheme.2 This should enable lawful and appropriate ADM across government and update existing ADM provisions.

While whole-of-government efforts progress, we will also progress lateral conversations with policy agencies to work towards legislation that supports the use of emerging technology by service delivery staff.

Practically, we have and will continue to identify opportunities to collaboratively reform legislation, so we can process claims faster, more accurately and consistently, and free up time to provide tailored support to customers in need.

# Priority 5: Uplift our workforce capability and capacity required to develop and manage automation and AI safely, ethically, and responsibly

Barrier: Limited people capability to safely build and manage automation and AI

Context: Research by Gartner notes that access to available skills is a key barrier to effective technology transformation and AI adoption.

In a report from Cisco, it was found that 92 percent of jobs in the study were expected to undergo either high or moderate transformation due to advancements in AI.29 This presents a significant challenge to both public and private sector organisations seeking to leverage automation and AI to improve outcomes for customers and staff.

Building a workforce with the right skills and knowledge is vital in achieving the Data and Digital Government Strategy of “delivering simple, secure and connected public services, for all people and business, through world class data and digital capabilities”. The APS Employee Value Proposition (EVP) plays an important role in attracting talent to support our capability uplift, in a time of significant demand.30 This is reflected in our focus on upskilling and reskilling our APS workforce and attracting new talent.

A report by McKinsey and Company found by 2030 the need for technological skills will increase by $5 5 %$ .31 In 2024, the United States Department of Homeland Security (US DHS) began recruiting for 50 seasoned AI experts and technologists, to support AI development within their department. 32 In addition, the US DHS invested in and continues to invest in training across their workforce, to ensure staff felt comfortable interacting with and leveraging various AI tools.

Automation and AI requires us to change the way some tasks are performed and adapt to new ways of working. This requires close consultation with staff and stakeholders, and additional guidance and education for our staff to support these changes and ensure the agency can effectively deliver and sustain successful automation and AI. Aligned to the DTA Policy for the responsible use of AI in government, and agency commitments to our staff, we’ll invest in:

AI fundamentals and ongoing training for all staff, aligned to the approach under the policy guidance,

within 6 months of the policy taking effect in 2024

additional training for staff considering their roles and responsibilities, such as those responsible for

the procurement, development, training and deployment of AI systems

fully sponsored staff qualifications with Australian Universities

micro-credentialling through the APSC’s capabilities uplift

defining and recognising talent through the Aurora Neuroinclusion Program and Entry Level Programs

# Priority 6: Modular, connected and standardised systems to enable scalable initiatives to be delivered

Barrier: Limited infrastructure and interoperability

Context: Respondents to a report conducted by McKinsey with representation from various regions, sectors and company sizes noted one of the top 5 barriers to generating value from AI (with application to automation) was limited technological infrastructure.33

Accordingly, an organisation’s ability to respond to customer needs via emerging technology and interoperability may be limited by legacy and monolithic infrastructure, systems and data assets that cannot be readily integrated. This may increase resource requirements, disruption, and costs, limiting the effective deployment of automation and AI capability at speed and scale.

Governance of the data stored and processed by automation and AI systems is an important function that ensures the quality, integrity and security of the data is maintained throughout the automation and AI Initiative Pathway. Careful management, and potentially tracking, of data accessibility and usage will also be required. Data, automation and AI governance should also incorporate capabilities to evaluate the ethics and explainability of the solutions.

As an agency, we have a strong record of delivering high quality, safe and accessible technology that people use every day. Our challenge is to ensure we take advantage of new opportunities and add value to our capabilities and capacity. We set our sights high and imagine a future state where our technology landscape empowers the agency to respond promptly, efficiently and empathetically to the needs of our customers.

We are focused on how our technology and digital capabilities progress us towards our future state, where innovation supports how we interact with our customers and stakeholders - streamlining services, building trust in our platforms and enhancing accessibility through cutting edge solutions. We will lawfully and ethically leverage capabilities of automation and AI to create a tailored and targeted customer experience. We will focus on uplifting secure and resilient infrastructure, software and technical foundations while driving delivery efficiencies. In doing so, our goal is to provide a trusted and integrated portfolio of whole-of-government digital and legacy technology, delivering data and functionality that maintains safe, secure and resilient capability that can be scaled to meet demands.

Given the size of our operations, even small changes can have a significant impact on customers, users and government reputation. Therefore, change must happen within a control framework to ensure that its impact is managed efficiently and effectively. We will continue to review our technology stack to support our plans to improve technical resilience and minimise complexity. Strong, secure infrastructure foundations will deliver services in times of need, whilst leveraging new and emerging technologies to scale innovative and uplifted services to staff and customers where it is beneficial.

# Build versus buy

We have a range of options when considering implementing an automation or AI solution, to be assessed caseby-case, including:

• buying or licensing automation products (including AI)

optimising or customising third party automation models for our own use using our own data building automation or AI models ourselves

The criteria of decision-making will be based on factors including whether it is fit for purpose, its accuracy, maintainability, ongoing monitoring, workforce requirements, tuning requirements and explainability.

Benefits of building in-house automation and AI models may include (but are not limited to) leveraging internal information in the model building process, building models using data sets more relevant to Australians, building institutional knowledge, familiarity with agency data and processes, ownership over the maintenance and intellectual property, and the ability to better explain automation and AI, offering full transparency of the model.

In contrast, the benefits to buying or licensing commercial automation models may include lower build cost, rapid deployment due to commercial validation, maintenance is owned by an external party, the ability to use expertise in the market, and leveraging innovation of other sectors.

# Measuring success

We’ll know we’re succeeding when:

we’re using automation and AI in a responsible, ethical, lawful, transparent and safe manner to deliver value to customers and government.

there is an automation and AI governance forum upholding global best practice and standards, supported by a multi-disciplinary team from across the agency.

we have robust assurance practices defined which are transparent with customers on how their data is used and stored.

automation and AI innovation is supported with low-risk ideas moving in a swift but controlled manner, from ideation to discovery and implementation.

we routinely generate valuable and viable use cases, and through strategic investment, engaging with automation and AI systems to stay up to date with the technology curve.

our skills and knowledge have been uplifted in automation and AI, not only for practitioners, but also the senior leadership team, service officers and enabling staff. There is a foundational awareness of automation and AI for our users in knowing how to safely and ethically interact with emerging technologies.

# Appendix A

# Government Landscape

The Australian Government recognises the potential for automation and AI technologies to help improve wellbeing, increase quality of life and grow the national economy. However, low public trust that systems are being designed, developed, deployed and used safely and responsibly is impacting adoption and public acceptance. 17

Several departments are leading key initiatives to support the application of automation and AI across the APS, including:

The DTA Policy for the responsible use of AI in government, aimed to support the public service to embrace the benefits of AI, strengthen public trust and contribute to a culture of adapting over time The whole-of-government automation community of practice led by the Department of Finance, promoting awareness and a broader understanding of the automation challenges faced by government departments and agencies The AI in Government Taskforce has recognised the need for a consistent, whole-of-government definition of automation, highlighting this as a consideration in the Survey of ADM in government

In June 2023, the Data and Digital Ministers Meeting (DDMM) agreed to work towards a nationally consistent approach to the safe and ethical use of AI by governments, regardless of state and territory borders or levels of government. This is supported by a cross-jurisdiction working group, chaired by the Commonwealth and NSW Governments. The NSW Artificial Intelligence Assurance Framework (Digital NSW, 2022) - one of the first in the world – was used as a baseline to ultimately develop a national framework which was released in June 2024. We are aligning assurance of AI use to this framework, which sets a nationally consistent approach based on Australia’s AI Ethics Principles.

The framework will help achieve safer, more reliable and fairer outcomes for all Australians, reduce the risk of negative impact on those affected by AI and will hold the government to the highest ethical standards when designing, developing and implementing AI systems. It’s built around 5 mechanisms – governance, data governance, a risk-based approach, standards and procurement –ensuring effective application of the AI Ethics Principles. The framework is complemented by existing regulatory safeguards including consumer, corporate, criminal, online safety, administrative, copyright, intellectual property and privacy laws.

# International Landscape

International governments are actively adopting automation and AI technologies to enhance decision making, improve public service delivery, and drive economic growth. A report published by the Deloitte Centre for Government Insights34 identified over 200 case studies where the convergence of technology with process, policy, workforce and regulatory innovation has enabled governments to improve service delivery outcomes for customers and government staff. For example, the US DHS has released the AI powered chatbot, DHSChat, designed exclusively for their department and available to their roughly 19,000 employees. DHSChat assists employees to perform routine work more efficiently, including summarising documentation, generating computer code, and streamlining repetitive tasks like data entry.

Several nations including the United States, the European Union, the United Kingdom and Canada have introduced legislation or made plans to regulate AI. It is important to note, as AI evolves and the political environment shifts, introduction of legislation or regulation plans may change. In 2023, G7 countries agreed that all advanced nations should adopt risk-based regulation on AI that preserves an open and enabling environment, based on democratic values.35

Shortly thereafter, Europe became the first major government to implement comprehensive and binding AI regulations with the Artificial Intelligence Act, addressing the need for transparency, use of AI in public spaces, and high-risk systems. Holding regulation in tension with innovation remains a challenge with commentary that the prescriptive legislation may stifle progress.36

To date, Australia has sought to hold regulation and innovation in tension, with federal guidance supported by aligned and coordinated frameworks. Specifically, the federal, state and territory governments will develop and align their own assurance policies and guidelines to the national framework. This approach affords flexibility for a jurisdiction’s unique needs while defining consistent expectations for oversight of AI and people’s experience of government. It also commits Australian governments to continue this collaboration and share their learnings on AI assurance to evolve the national framework.

1 Services Australia annual report 2023-24

2 Australia’s AI Ethics Principles \| Australia’s Artificial Intelligence Ethics Framework \| Department of Industry Science

3 Ombudsman's Automated Decision-Making Guide

4 Policy for the responsible use of AI in government \| digital.gov.au

5 National Framework for the Assurance of Artificial Intelligence in Government

6 APS Workforce Strategy 2025 \| Australian Public Service Commission (apsc.gov.au)

7 Corporate plan 2024-25

8 OECD revised definition of an AI system

9 APS Vision for user-centred service excellence

10 AI, automation, and the future of work: Ten things to solve for (Tech4Good) \| McKinsey

11 How artificial intelligence will transform decision-making \| World Economic Forum

12 How AI Can Help Leaders Make Better Decisions Under Pressure

13 How GenAI Could Accelerate Employee Learning and Development

14 Artificial intelligence in advancing occupational health and safety: an encapsulation of developments

15 The AI Revolution Transforming Hybrid And Remote Work And The Return To Office

16 How AI Is Changing The Way We Communicate

17 How might artificial intelligence affect the trustworthiness of public service delivery? (pmc.gov.au)

18 A survey of over 17,000 people indicates only half of us are willing to trust AI at work (theconversation.com)

19 3 Barriers to AI Adoption (gartner.com)

20 PDPC \| Singapore’s Approach to AI Governance

21 Home \| Data and Digital

22 Transparency Statements \| DTA

23 Tech Should Enable Change, Not Drive It (hbr.org)

24 Investing in Digital Technology: Overcoming the Challenges \| BCG

25 Bridging the gap in understanding AI governance (aicd.com.au)

26 National framework for the assurance of artificial intelligence in government

27 Reducing the complexity of legislation \| Attorney-General's Department (ag.gov.au)

28 EU AI Act: first regulation on artificial intelligence \| Topics \| European Parliament

29 AI and the Workforce: Industry Report Calls for Reskilling and Upskilling as 92 Percent of Technology Roles Evolve

30 APS Employee Value Proposition \| Australian Public Service Commission (apsc.gov.au)

31 Automation and the workforce of the future \| McKinsey

32 DHS’s Responsible Use of Generative AI Tools \| Homeland Security

33 Adoption of AI advances, but foundational barriers remain \| McKinsey

34 10x government \| Deloitte Insights

35 G7 Ministerial Declaration - GOV.UK ( [www.gov.uk](http://www.gov.uk/))

36 Europe’s rushed attempt to set the rules for AI (ft.com)